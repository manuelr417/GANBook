{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Training for Camel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.GAN import GAN\n",
    "from utils.loaders import load_safari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'camel'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = load_safari(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13b2d5518>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[200,:,:,0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0404 16:02:08.818917 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0404 16:02:08.858695 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0404 16:02:08.883909 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0404 16:02:08.886159 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0404 16:02:08.898427 140734743788992 deprecation.py:506] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0404 16:02:09.207205 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0404 16:02:09.242383 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0404 16:02:09.381399 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0404 16:02:09.644590 140734743788992 deprecation_wrapper.py:119] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0404 16:02:09.653548 140734743788992 deprecation.py:323] From /Users/manuel/python_venvs/gdlbook/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(input_dim = (28,28,1)\n",
    "        , discriminator_conv_filters = [64,64,128,128]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,1]\n",
    "        , discriminator_batch_norm_momentum = None\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout_rate = 0.4\n",
    "        , discriminator_learning_rate = 0.0008\n",
    "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "        , generator_upsample = [2,2, 1, 1]\n",
    "        , generator_conv_filters = [128,64, 64,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout_rate = None\n",
    "        , generator_learning_rate = 0.0004\n",
    "        , optimiser = 'rmsprop'\n",
    "        , z_dim = 100\n",
    "        )\n",
    "\n",
    "if mode == 'build':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1000\n",
    "PRINT_EVERY_N_BATCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(     \n",
    "    x_train\n",
    "    , batch_size = BATCH_SIZE\n",
    "    , epochs = EPOCHS\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdlbook",
   "language": "python",
   "name": "gdlbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
